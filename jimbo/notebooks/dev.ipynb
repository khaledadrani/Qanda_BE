{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15854bab",
   "metadata": {},
   "source": [
    "# setup notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "933508cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Documents\\\\garage\\\\qanda\\\\JIMBO\\\\jimbo\\\\notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f40aea5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\garage\\qanda\\JIMBO\\jimbo\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5097bf90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Documents\\\\garage\\\\qanda\\\\JIMBO\\\\jimbo'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd #should be D:\\\\Documents\\\\garage\\\\JIMBO\\\\jimbo' (Windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "909cf5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"./my_django_app/settings.py\")\n",
    "os.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\" #do not use in production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5b93371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import django\n",
    "django.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4af4f1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from django.conf import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cb25e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qa.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf6376ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = Problem.objects.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ae2e7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59939dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = Problem.objects.filter(id=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b80a220d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem(5,What is your name?)\n"
     ]
    }
   ],
   "source": [
    "for q in qs:\n",
    "    print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cd48d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Problem: Problem(4,What is your name?)>,\n",
       " <Problem: Problem(5,What is your name?)>,\n",
       " <Problem: Problem(6,What is your name?)>,\n",
       " <Problem: Problem(7,What is my name?)>,\n",
       " <Problem: Problem(8,What is your name?)>,\n",
       " <Problem: Problem(9,What is your name?)>,\n",
       " <Problem: Problem(10,What is your name?)>,\n",
       " <Problem: Problem(11,What is your name?)>,\n",
       " <Problem: Problem(12,What is your name?)>,\n",
       " <Problem: Problem(13,What is your name?)>,\n",
       " <Problem: Problem(17,What is your name?)>,\n",
       " <Problem: Problem(18,What is your name?)>,\n",
       " <Problem: Problem(19,What is your name?)>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3f7e426",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'status_code'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdjango\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhttp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HttpResponse,JsonResponse\n\u001b[1;32m----> 3\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mJsonResponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Documents\\garage\\JIMBO\\env\\lib\\site-packages\\django\\http\\response.py:654\u001b[0m, in \u001b[0;36mJsonResponse.__init__\u001b[1;34m(self, data, encoder, safe, json_dumps_params, **kwargs)\u001b[0m\n\u001b[0;32m    652\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    653\u001b[0m data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(data, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39mencoder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mjson_dumps_params)\n\u001b[1;32m--> 654\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(content\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Documents\\garage\\JIMBO\\env\\lib\\site-packages\\django\\http\\response.py:353\u001b[0m, in \u001b[0;36mHttpResponse.__init__\u001b[1;34m(self, content, *args, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 353\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;66;03m# Content is a bytestring. See the `content` property methods.\u001b[39;00m\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;241m=\u001b[39m content\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'status_code'"
     ]
    }
   ],
   "source": [
    "from django.http import HttpResponse,JsonResponse\n",
    "\n",
    "response = JsonResponse(data={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "688cf2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method HttpResponseBase.items of <JsonResponse status_code=200, \"application/json\">>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e26807f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__bytes__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_charset',\n",
       " '_container',\n",
       " '_content_type_for_repr',\n",
       " '_handler_class',\n",
       " '_reason_phrase',\n",
       " '_resource_closers',\n",
       " 'charset',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'content',\n",
       " 'cookies',\n",
       " 'delete_cookie',\n",
       " 'flush',\n",
       " 'get',\n",
       " 'getvalue',\n",
       " 'has_header',\n",
       " 'headers',\n",
       " 'items',\n",
       " 'make_bytes',\n",
       " 'readable',\n",
       " 'reason_phrase',\n",
       " 'seekable',\n",
       " 'serialize',\n",
       " 'serialize_headers',\n",
       " 'set_cookie',\n",
       " 'set_signed_cookie',\n",
       " 'setdefault',\n",
       " 'status_code',\n",
       " 'streaming',\n",
       " 'tell',\n",
       " 'writable',\n",
       " 'write',\n",
       " 'writelines']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96e6934",
   "metadata": {},
   "source": [
    "# workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "381300c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'end': 24,\n",
       " 'score': 0.9924208521842957,\n",
       " 'start': 11,\n",
       " 'answer': 'Khaled Adrani'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item.answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bae94927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<django.db.models.fields.AutoField: id>,\n",
       " <django.db.models.fields.CharField: question>,\n",
       " <django.db.models.fields.CharField: context>,\n",
       " <django.db.models.fields.CharField: model_name>,\n",
       " <django.db.models.fields.json.JSONField: answer>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model_fields(model):\n",
    "    return [f.name for f in model._meta.get_fields()]\n",
    "\n",
    "fields = get_model_fields(Problem)\n",
    "list(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c3bdb2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'question', 'context', 'model_name', 'answer']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f.name for f in fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6b92593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem(4,What is your name?)\n",
      "\n",
      "Problem(5,What is your name?)\n",
      "\n",
      "Problem(6,What is your name?)\n",
      "\n",
      "Problem(7,What is my name?)\n",
      "\n",
      "Problem(8,What is your name?)\n",
      "\n",
      "Problem(9,What is your name?)\n",
      "\n",
      "Problem(10,What is your name?)\n",
      "\n",
      "Problem(11,What is your name?)\n",
      "\n",
      "Problem(12,What is your name?)\n",
      "\n",
      "Problem(13,What is your name?)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "items = Problem.objects.all()\n",
    "for item in items:\n",
    "    print(item)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd3dd2e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdjango\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandlers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwsgi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WSGIRequest\n\u001b[1;32m----> 3\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[43mWSGIRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjimbo.wsgi.application\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Documents\\garage\\JIMBO\\env\\lib\\site-packages\\django\\core\\handlers\\wsgi.py:66\u001b[0m, in \u001b[0;36mWSGIRequest.__init__\u001b[1;34m(self, environ)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, environ):\n\u001b[1;32m---> 66\u001b[0m     script_name \u001b[38;5;241m=\u001b[39m \u001b[43mget_script_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# If PATH_INFO is empty (e.g. accessing the SCRIPT_NAME URL without a\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# trailing slash), operate as if '/' was requested.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     path_info \u001b[38;5;241m=\u001b[39m get_path_info(environ) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mD:\\Documents\\garage\\JIMBO\\env\\lib\\site-packages\\django\\core\\handlers\\wsgi.py:178\u001b[0m, in \u001b[0;36mget_script_name\u001b[1;34m(environ)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m settings\u001b[38;5;241m.\u001b[39mFORCE_SCRIPT_NAME\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# If Apache's mod_rewrite had a whack at the URL, Apache set either\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# SCRIPT_URL or REDIRECT_URL to the full resource URL before applying any\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;66;03m# rewrites. Unfortunately not every web server (lighttpd!) passes this\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;66;03m# information through all the time, so FORCE_SCRIPT_NAME, above, is still\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;66;03m# needed.\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m script_url \u001b[38;5;241m=\u001b[39m \u001b[43mget_bytes_from_wsgi\u001b[49m\u001b[43m(\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSCRIPT_URL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m get_bytes_from_wsgi(\n\u001b[0;32m    179\u001b[0m     environ, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREDIRECT_URL\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    180\u001b[0m )\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m script_url:\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m script_url:\n\u001b[0;32m    184\u001b[0m         \u001b[38;5;66;03m# mod_wsgi squashes multiple successive slashes in PATH_INFO,\u001b[39;00m\n\u001b[0;32m    185\u001b[0m         \u001b[38;5;66;03m# do the same with script_url before manipulating paths (#17133).\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Documents\\garage\\JIMBO\\env\\lib\\site-packages\\django\\core\\handlers\\wsgi.py:201\u001b[0m, in \u001b[0;36mget_bytes_from_wsgi\u001b[1;34m(environ, key, default)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_bytes_from_wsgi\u001b[39m(environ, key, default):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03m    Get a value from the WSGI environ dictionary as bytes.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03m    key and default should be strings.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 201\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43menviron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(key, default)\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m# Non-ASCII values in the WSGI environ are arbitrarily decoded with\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# ISO-8859-1. This is wrong for Django websites where UTF-8 is the default.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;66;03m# Re-encode to recover the original bytestring.\u001b[39;00m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "from django.core.handlers.wsgi import WSGIRequest\n",
    "\n",
    "request = WSGIRequest('jimbo.wsgi.application')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c93e3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class WSGIRequest in module django.core.handlers.wsgi:\n",
      "\n",
      "class WSGIRequest(django.http.request.HttpRequest)\n",
      " |  WSGIRequest(environ)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      WSGIRequest\n",
      " |      django.http.request.HttpRequest\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  COOKIES = <django.utils.functional.cached_property object>\n",
      " |  GET = <django.utils.functional.cached_property object>\n",
      " |  __init__(self, environ)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  FILES\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  POST\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from django.http.request.HttpRequest:\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  accepted_types = <django.utils.functional.cached_property object>\n",
      " |      Return a list of MediaType instances.\n",
      " |  \n",
      " |  accepts(self, media_type)\n",
      " |  \n",
      " |  build_absolute_uri(self, location=None)\n",
      " |      Build an absolute URI from the location and the variables available in\n",
      " |      this request. If no ``location`` is specified, build the absolute URI\n",
      " |      using request.get_full_path(). If the location is absolute, convert it\n",
      " |      to an RFC 3987 compliant URI and return it. If location is relative or\n",
      " |      is scheme-relative (i.e., ``//example.com/``), urljoin() it to a base\n",
      " |      URL constructed from the request variables.\n",
      " |  \n",
      " |  close(self)\n",
      " |  \n",
      " |  get_full_path(self, force_append_slash=False)\n",
      " |  \n",
      " |  get_full_path_info(self, force_append_slash=False)\n",
      " |  \n",
      " |  get_host(self)\n",
      " |      Return the HTTP host using the environment or request headers.\n",
      " |  \n",
      " |  get_port(self)\n",
      " |      Return the port number for the request as a string.\n",
      " |  \n",
      " |  get_signed_cookie(self, key, default=<object object at 0x000001E90218FC50>, salt='', max_age=None)\n",
      " |      Attempt to return a signed cookie. If the signature fails or the\n",
      " |      cookie has expired, raise an exception, unless the `default` argument\n",
      " |      is provided,  in which case return that value.\n",
      " |  \n",
      " |  headers = <django.utils.functional.cached_property object>\n",
      " |  is_secure(self)\n",
      " |  \n",
      " |  parse_file_upload(self, META, post_data)\n",
      " |      Return a tuple of (POST QueryDict, FILES MultiValueDict).\n",
      " |  \n",
      " |  read(self, *args, **kwargs)\n",
      " |  \n",
      " |  readline(self, *args, **kwargs)\n",
      " |  \n",
      " |  readlines(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from django.http.request.HttpRequest:\n",
      " |  \n",
      " |  body\n",
      " |  \n",
      " |  scheme\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from django.http.request.HttpRequest:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  encoding\n",
      " |  \n",
      " |  upload_handlers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(WSGIRequest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "117f65b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest.mock import Mock\n",
    "\n",
    "request = Mock()\n",
    "request.data = {'Document_library': 18,\n",
    "                'api_request_number': 1000, \n",
    "                'queries': \n",
    "                [\n",
    "                 #{'query_type': 'author', 'query_value': 'roland kawakami'}, \n",
    "                 {'query_type': 'keyword', 'query_value': 'graphene'}\n",
    "                 ]\n",
    "                }\n",
    "\n",
    "def mock_len():\n",
    "    return 0\n",
    "# request.__len__ =  mock_len\n",
    "# len(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21582ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------PROCEED to function GET_FILES_LIST------\n",
      "Proceed Scholar query\n",
      "number  1000\n",
      "number  graphene\n",
      "REQUEST URL  http://api.semanticscholar.org/graph/v1/paper/search?query=graphene&offset=0&limit=100&fields=paperId,externalIds,url,title,abstract,venue,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy,s2FieldsOfStudy,authors\n",
      "STATUS CODE 0:  200\n",
      "REQUEST URL REQUEST URL  REQUEST URL REQUEST URL  http://api.semanticscholar.org/graph/v1/paper/search?query=graphene&offset=100&limit=100&fields=paperId,externalIds,url,title,abstract,venue,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy,s2FieldsOfStudy,authors REQUEST URL  REQUEST URL REQUEST URL http://api.semanticscholar.org/graph/v1/paper/search?query=graphene&offset=300&limit=100&fields=paperId,externalIds,url,title,abstract,venue,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy,s2FieldsOfStudy,authorshttp://api.semanticscholar.org/graph/v1/paper/search?query=graphene&offset=400&limit=100&fields=paperId,externalIds,url,title,abstract,venue,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy,s2FieldsOfStudy,authors \n",
      "http://api.semanticscholar.org/graph/v1/paper/search?query=graphene&offset=200&limit=100&fields=paperId,externalIds,url,title,abstract,venue,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy,s2FieldsOfStudy,authorsREQUEST URL  REQUEST URL  \n",
      "\n",
      "http://api.semanticscholar.org/graph/v1/paper/search?query=graphene&offset=500&limit=100&fields=paperId,externalIds,url,title,abstract,venue,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy,s2FieldsOfStudy,authorshttp://api.semanticscholar.org/graph/v1/paper/search?query=graphene&offset=600&limit=100&fields=paperId,externalIds,url,title,abstract,venue,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy,s2FieldsOfStudy,authors\n",
      "  http://api.semanticscholar.org/graph/v1/paper/search?query=graphene&offset=700&limit=100&fields=paperId,externalIds,url,title,abstract,venue,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy,s2FieldsOfStudy,authors\n",
      "\n",
      "http://api.semanticscholar.org/graph/v1/paper/search?query=graphene&offset=900&limit=100&fields=paperId,externalIds,url,title,abstract,venue,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy,s2FieldsOfStudy,authorshttp://api.semanticscholar.org/graph/v1/paper/search?query=graphene&offset=800&limit=100&fields=paperId,externalIds,url,title,abstract,venue,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy,s2FieldsOfStudy,authors\n",
      "\n",
      "\n",
      "STATUS CODE 900:  200\n",
      "STATUS CODE 300:  200\n",
      "STATUS CODE 200:  200\n",
      "STATUS CODE 600:  200\n",
      "STATUS CODE 700:  200\n",
      "STATUS CODE 500:  200\n",
      "STATUS CODE 100:  200\n",
      "STATUS CODE 800:  200\n",
      "STATUS CODE 400:  200\n",
      "DF length after validation 775\n",
      "DF length after limiting to requested size 775\n",
      "MONITOR SIZE DF  1206807\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'Mock' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ls \u001b[38;5;241m=\u001b[39m \u001b[43mget_files_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Documents\\ubiai\\nlp\\Science_NLP_BE\\documents\\utils.py:63\u001b[0m, in \u001b[0;36mtimer.<locals>.wrapper_timer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-------PROCEED to function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     62\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 63\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     64\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     65\u001b[0m duration \u001b[38;5;241m=\u001b[39m end \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mD:\\Documents\\ubiai\\nlp\\Science_NLP_BE\\documents\\data_import.py:338\u001b[0m, in \u001b[0;36mget_files_list\u001b[1;34m(request, lib_id)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo Scholar query\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request\u001b[38;5;241m.\u001b[39mFILES \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFILES\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetlist\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDocument_file\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    339\u001b[0m     document_files \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mFILES\u001b[38;5;241m.\u001b[39mgetlist(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDocument_file\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'Mock' has no len()"
     ]
    }
   ],
   "source": [
    "from documents.data_import import get_files_list \n",
    "ls = get_files_list(request,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2731ae",
   "metadata": {},
   "source": [
    "## Clustering analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fff3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_entities(info_list):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    texts = []\n",
    "    for e in info_list:\n",
    "        doc_info = [word.lower() for word in e if word.lower() not in stop_words]\n",
    "        texts.append(doc_info)\n",
    "\n",
    "    texts = [\" \".join(ls) for ls in texts]\n",
    "\n",
    "    texts = [ls.split(' ') for ls in texts]\n",
    "\n",
    "    new_texts = []\n",
    "    for t in texts:\n",
    "      new_texts.append([w for w in t if w.lower() not in stop_words])\n",
    "\n",
    "    return new_texts\n",
    "\n",
    "texts = preprocess_entities(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230d000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(texts):\n",
    "    features = [] \n",
    "    vector_size = 100\n",
    "    wv_model = Word2Vec(sentences=texts,vector_size=vector_size,sg=1,window=10,min_count=1,workers=4,epochs=20)\n",
    "\n",
    "    missings = []\n",
    "    for document in texts: \n",
    "        vectors = []\n",
    "        if len(document)>0:\n",
    "            for word in document: \n",
    "              if word in wv_model.wv:\n",
    "                vectors.append(wv_model.wv[word])\n",
    "              else:\n",
    "                missings.append(word)\n",
    "                print('missing')\n",
    "                vectors.append(np.array([0.0 for i in range(vector_size)]))\n",
    "\n",
    "        vectors = np.asarray(vectors)\n",
    "        avg_vec = vectors.mean(axis=0)\n",
    "        features.append(avg_vec)\n",
    "    return features,wv_model\n",
    "\n",
    "\n",
    "features, wv_model = get_embeddings(texts)\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b689178",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import umap.umap_ as umap\n",
    "import hdbscan\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def get_clusters(features):\n",
    "  X = features\n",
    "\n",
    "  if len(X)>20:\n",
    "    min_cluster_size_value = int(len(X) / 10 )\n",
    "  else:\n",
    "    min_cluster_size_value = 2 \n",
    "\n",
    "  print('min_cluster_size_value ',min_cluster_size_value)\n",
    "\n",
    "  X_emb = umap.UMAP(n_neighbors=5,min_dist=0.0,n_components=2,\n",
    "      metric='cosine',random_state=42).fit_transform(X)\n",
    "\n",
    "  # pca = PCA(n_components=2)\n",
    "  # X_emb = pca.fit_transform(X)\n",
    "\n",
    "  cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size_value,min_samples=5, \n",
    "      metric='euclidean',cluster_selection_method='eom').fit(X_emb) \n",
    "  y_pred = cluster.labels_\n",
    "\n",
    "  return X_emb,y_pred\n",
    "\n",
    "\n",
    "X_emb,y_pred = get_clusters(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adda00ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "def get_graph(X_emb,y_pred):\n",
    "  df = pd.DataFrame() \n",
    "  df['x'] = [e[0] for e in X_emb]\n",
    "  df['y'] = [e[1] for e in X_emb]\n",
    "  df['cluster'] = y_pred\n",
    "\n",
    "  sns.lmplot( x=\"x\", y=\"y\", data=df, fit_reg=False, hue='cluster', legend=False)\n",
    "  # Move the legend to an empty part of the plot\n",
    "  plt.legend(loc='lower left')\n",
    "  plt.show()\n",
    "\n",
    "get_graph(X_emb,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b4a259",
   "metadata": {},
   "source": [
    "## similarity computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d6db4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.stats import spearmanr as spearman\n",
    "\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7596db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cosine_distances(X, Y):\n",
    "    \"\"\"\n",
    "    Considering the rows of X (and Y=X) as vectors, compute the\n",
    "    distance matrix between each pair of vectors.\n",
    "\n",
    "     An implementation of the cosine similarity. The result is the cosine of\n",
    "     the angle formed between the two preference vectors.\n",
    "     Note that this similarity does not \"center\" its data, shifts the user's\n",
    "     preference values so that each of their means is 0. For this behavior,\n",
    "     use Pearson Coefficient, which actually is mathematically\n",
    "     equivalent for centered data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: array of shape (n_samples_1, n_features)\n",
    "\n",
    "    Y: array of shape (n_samples_2, n_features)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    distances: array of shape (n_samples_1, n_samples_2)\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from crab.metrics.pairwise  import cosine_distances\n",
    "    >>> X = [[2.5, 3.5, 3.0, 3.5, 2.5, 3.0],[2.5, 3.5, 3.0, 3.5, 2.5, 3.0]]\n",
    "    >>> # distance between rows of X\n",
    "    >>> cosine_distances(X, X)\n",
    "    array([[ 1.,  1.],\n",
    "          [ 1.,  1.]])\n",
    "    >>> cosine_distances(X, [[3.0, 3.5, 1.5, 5.0, 3.5,3.0]])\n",
    "    array([[ 0.9606463],\n",
    "           [ 0.9606463]])\n",
    "\n",
    "    \"\"\"\n",
    "    #TODO: implement this check\n",
    "    #X, Y = check_pairwise_arrays(X, Y)\n",
    "\n",
    "    #TODO: Fix to work with sparse matrices.\n",
    "    if issparse(X) or issparse(Y):\n",
    "        raise ValueError('Cosine does not yet support sparse matrices.')\n",
    "\n",
    "    return 1. - ssd.cdist(X, Y, 'cosine')\n",
    "\n",
    "res_sim = cosine_distances(X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "243923a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(774, 774)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccc1d618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([256, 516, 140, 402, 378], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08d7af2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Doc_atr: Doc_atr object (1)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from documents.models import * \n",
    "\n",
    "item = Doc_atr.objects.first()\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec9c9f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([256, 516, 140, 402, 378,   0], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = np.argpartition(res[0], -6)[-6:]\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "285194c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([256, 516, 140, 402, 378], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = ind[ind!=0]\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81c79260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18789, 19049, 18673, 18935, 18911]\n"
     ]
    }
   ],
   "source": [
    "ind = np.argpartition(res[0], -6)[-6:][:5]\n",
    "sims = [all_id[index] for index in ind]\n",
    "print(sims)\n",
    "item.Doc_atr_vec_json['material']['sim'] = sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ee5b2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "libraryId = 53 #graphene\n",
    "update_x_list=Doc_atr.objects.filter(documents__Document_library_id=libraryId).order_by('Doc_atr_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14fdfd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\khale\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------PROCEED to function LOAD_VECTORS_INFO------\n",
      "\t LOAD_VECTORS_INFO Duration:  0.3461337089538574\n"
     ]
    }
   ],
   "source": [
    "from documents.data_analysis import *\n",
    "\n",
    "X=load_vectors_info(libraryId,'material')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e6a6e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------PROCEED to function LOAD_ALL_ID------\n",
      "\t LOAD_ALL_ID Duration:  0.0029981136322021484\n"
     ]
    }
   ],
   "source": [
    "all_id = load_all_id(libraryId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1fb5e4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18789, 19049, 18673, 18935, 18911]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = [all_id[index] for index in ind]\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9cc4ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = cosine_distances(X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "805954c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "libraryId=52\n",
    "info = 'material'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c7ae97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------PROCEED to function LOAD_VECTORS_INFO------\n",
      "\t LOAD_VECTORS_INFO Duration:  0.18682360649108887\n",
      "-------PROCEED to function LOAD_ALL_ID------\n",
      "\t LOAD_ALL_ID Duration:  0.001999378204345703\n",
      "ind  [180  71   1 110 109   0]\n",
      "ind after  [180  71   1 110 109]\n",
      "done\n",
      "\n",
      "ind  [  0 156  47   1 110 109]\n",
      "ind after  [  0 156  47 110 109]\n",
      "done\n",
      "\n",
      "ind  [ 69 178 123  14   2 111]\n",
      "ind after  [ 69 178 123  14 111]\n",
      "done\n",
      "\n",
      "ind  [190  81 140 112   3  31]\n",
      "ind after  [190  81 140 112  31]\n",
      "done\n",
      "\n",
      "ind  [206  97 160 113   4  51]\n",
      "ind after  [206  97 160 113  51]\n",
      "done\n",
      "\n",
      "ind  [ 52  60 114   5 169 161]\n",
      "ind after  [ 52  60 114 169 161]\n",
      "done\n",
      "\n",
      "ind  [153  30   6 139  44 115]\n",
      "ind after  [153  30 139  44 115]\n",
      "done\n",
      "\n",
      "ind  [103 212 165  56   7 116]\n",
      "ind after  [103 212 165  56 116]\n",
      "done\n",
      "\n",
      "ind  [ 41 150 148  39   8 117]\n",
      "ind after  [ 41 150 148  39 117]\n",
      "done\n",
      "\n",
      "ind  [ 39 148 118   9   8 117]\n",
      "ind after  [ 39 148 118   8 117]\n",
      "done\n",
      "\n",
      "ind  [117 118  10   9   8 119]\n",
      "ind after  [117 118   9   8 119]\n",
      "done\n",
      "\n",
      "ind  [  9 118 119  10  11 120]\n",
      "ind after  [  9 118 119  10 120]\n",
      "done\n",
      "\n",
      "ind  [ 52 162 161  12 121  53]\n",
      "ind after  [ 52 162 161 121  53]\n",
      "done\n",
      "\n",
      "ind  [ 53 162  52 161 122  13]\n",
      "ind after  [ 53 162  52 161 122]\n",
      "done\n",
      "\n",
      "ind  [ 54 163 178 123  69  14]\n",
      "ind after  [ 54 163 178 123  69]\n",
      "done\n",
      "\n",
      "ind  [ 95 124  15 204  25 134]\n",
      "ind after  [ 95 124 204  25 134]\n",
      "done\n",
      "\n",
      "ind  [ 92 201  17 125 126  16]\n",
      "ind after  [ 92 201  17 125 126]\n",
      "done\n",
      "\n",
      "ind  [ 92 201  17 125 126  16]\n",
      "ind after  [ 92 201 125 126  16]\n",
      "done\n",
      "\n",
      "ind  [  5 114 185  76  18 127]\n",
      "ind after  [  5 114 185  76 127]\n",
      "done\n",
      "\n",
      "ind  [ 20 128  19 107 216 129]\n",
      "ind after  [ 20 128 107 216 129]\n",
      "done\n",
      "\n",
      "ind  [128  19 107  20 216 129]\n",
      "ind after  [128  19 107 216 129]\n",
      "done\n",
      "\n",
      "ind  [106 215  95  21 204 130]\n",
      "ind after  [106 215  95 204 130]\n",
      "done\n",
      "\n",
      "ind  [ 19 128 141  32 131  22]\n",
      "ind after  [ 19 128 141  32 131]\n",
      "done\n",
      "\n",
      "ind  [147  38 152  23 132  43]\n",
      "ind after  [147  38 152 132  43]\n",
      "done\n",
      "\n",
      "ind  [146  24 145  37 133  36]\n",
      "ind after  [146 145  37 133  36]\n",
      "done\n",
      "\n",
      "ind  [ 21 130 124  15 134  25]\n",
      "ind after  [ 21 130 124  15 134]\n",
      "done\n",
      "\n",
      "ind  [ 84 135 193  26 192  83]\n",
      "ind after  [ 84 135 193 192  83]\n",
      "done\n",
      "\n",
      "ind  [ 61 170  89 198 136  27]\n",
      "ind after  [ 61 170  89 198 136]\n",
      "done\n",
      "\n",
      "ind  [162  53  99 137  28 208]\n",
      "ind after  [162  53  99 137 208]\n",
      "done\n",
      "\n",
      "ind  [ 12 121  69 138  29 178]\n",
      "ind after  [ 12 121  69 138 178]\n",
      "done\n",
      "\n",
      "ind  [  6 115  44 153 139  30]\n",
      "ind after  [  6 115  44 153 139]\n",
      "done\n",
      "\n",
      "ind  [190  81  31 140   3 112]\n",
      "ind after  [190  81 140   3 112]\n",
      "done\n",
      "\n",
      "ind  [ 93 213 202 141 104  32]\n",
      "ind after  [ 93 213 202 141 104]\n",
      "done\n",
      "\n",
      "ind  [121  12  33 142  64 173]\n",
      "ind after  [121  12 142  64 173]\n",
      "done\n",
      "\n",
      "ind  [151  42  40 149  34 143]\n",
      "ind after  [151  42  40 149 143]\n",
      "done\n",
      "\n",
      "ind  [130  21 204  95 144  35]\n",
      "ind after  [130  21 204  95 144]\n",
      "done\n",
      "\n",
      "ind  [214 105  36 145 133  24]\n",
      "ind after  [214 105 145 133  24]\n",
      "done\n",
      "\n",
      "ind  [214 105  37  42 146 151]\n",
      "ind after  [214 105  42 146 151]\n",
      "done\n",
      "\n",
      "ind  [  8 117 148  39 147  38]\n",
      "ind after  [  8 117 148  39 147]\n",
      "done\n",
      "\n",
      "ind  [ 38 147   8 117 148  39]\n",
      "ind after  [ 38 147   8 117 148]\n",
      "done\n",
      "\n",
      "ind  [151  42  34 143  40 149]\n",
      "ind after  [151  42  34 143 149]\n",
      "done\n",
      "\n",
      "ind  [148  39  41 150   8 117]\n",
      "ind after  [148  39 150   8 117]\n",
      "done\n",
      "\n",
      "ind  [ 40 149 146  37  42 151]\n",
      "ind after  [ 40 149 146  37 151]\n",
      "done\n",
      "\n",
      "ind  [ 60 169  43  23 152 132]\n",
      "ind after  [ 60 169  23 152 132]\n",
      "done\n",
      "\n",
      "ind  [192 139  83  44  30 153]\n",
      "ind after  [192 139  83  30 153]\n",
      "done\n",
      "\n",
      "ind  [169  60 186  45  77 154]\n",
      "ind after  [169  60 186  77 154]\n",
      "done\n",
      "\n",
      "ind  [ 77 186  46 211 155 102]\n",
      "ind after  [ 77 186 211 155 102]\n",
      "done\n",
      "\n",
      "ind  [ 48 157 110  47   1 156]\n",
      "ind after  [ 48 157 110   1 156]\n",
      "done\n",
      "\n",
      "ind  [180  48  71 157 156  47]\n",
      "ind after  [180  71 157 156  47]\n",
      "done\n",
      "\n",
      "ind  [216 107 137 158  28  49]\n",
      "ind after  [216 107 137 158  28]\n",
      "done\n",
      "\n",
      "ind  [183  74 101 210 159  50]\n",
      "ind after  [183  74 101 210 159]\n",
      "done\n",
      "\n",
      "ind  [204  95 113 160   4  51]\n",
      "ind after  [204  95 113 160   4]\n",
      "done\n",
      "\n",
      "ind  [114   5 161  52 162  53]\n",
      "ind after  [114   5 161 162  53]\n",
      "done\n",
      "\n",
      "ind  [208  99  53 162 161  52]\n",
      "ind after  [208  99 162 161  52]\n",
      "done\n",
      "\n",
      "ind  [123  14  59  54 168 163]\n",
      "ind after  [123  14  59 168 163]\n",
      "done\n",
      "\n",
      "ind  [ 44 153  72 181 164  55]\n",
      "ind after  [ 44 153  72 181 164]\n",
      "done\n",
      "\n",
      "ind  [116   7 105 214 165  56]\n",
      "ind after  [116   7 105 214 165]\n",
      "done\n",
      "\n",
      "ind  [  8 117  57 215 106 166]\n",
      "ind after  [  8 117 215 106 166]\n",
      "done\n",
      "\n",
      "ind  [ 74 183 174  58  65 167]\n",
      "ind after  [ 74 183 174  65 167]\n",
      "done\n",
      "\n",
      "ind  [ 33 142 163 168  59  54]\n",
      "ind after  [ 33 142 163 168  54]\n",
      "done\n",
      "\n",
      "ind  [  5 114  96  60 205 169]\n",
      "ind after  [  5 114  96 205 169]\n",
      "done\n",
      "\n",
      "ind  [179 171 170  61  70  62]\n",
      "ind after  [179 171 170  70  62]\n",
      "done\n",
      "\n",
      "ind  [ 61 170  47 156  62 171]\n",
      "ind after  [ 61 170  47 156 171]\n",
      "done\n",
      "\n",
      "ind  [212 103 108 172  63 217]\n",
      "ind after  [212 103 108 172 217]\n",
      "done\n",
      "\n",
      "ind  [142  13 122  33 173  64]\n",
      "ind after  [142  13 122  33 173]\n",
      "done\n",
      "\n",
      "ind  [183  74  65  58 167 174]\n",
      "ind after  [183  74  58 167 174]\n",
      "done\n",
      "\n",
      "ind  [201  92 108 175  66 217]\n",
      "ind after  [201  92 108 175 217]\n",
      "done\n",
      "\n",
      "ind  [182  73  12 121  67 176]\n",
      "ind after  [182  73  12 121 176]\n",
      "done\n",
      "\n",
      "ind  [142  33 197  88  68 177]\n",
      "ind after  [142  33 197  88 177]\n",
      "done\n",
      "\n",
      "ind  [138  29  14 123  69 178]\n",
      "ind after  [138  29  14 123 178]\n",
      "done\n",
      "\n",
      "ind  [ 61 179 170  70  62 171]\n",
      "ind after  [ 61 179 170  62 171]\n",
      "done\n",
      "\n",
      "ind  [109   0 157 180  71  48]\n",
      "ind after  [109   0 157 180  48]\n",
      "done\n",
      "\n",
      "ind  [ 80 189  55 164  72 181]\n",
      "ind after  [ 80 189  55 164 181]\n",
      "done\n",
      "\n",
      "ind  [176 121  12 182  67  73]\n",
      "ind after  [176 121  12 182  67]\n",
      "done\n",
      "\n",
      "ind  [ 65 174  85 194  74 183]\n",
      "ind after  [ 65 174  85 194 183]\n",
      "done\n",
      "\n",
      "ind  [ 79 188  75  74 183 184]\n",
      "ind after  [ 79 188  74 183 184]\n",
      "done\n",
      "\n",
      "ind  [171  97  62 206 185  76]\n",
      "ind after  [171  97  62 206 185]\n",
      "done\n",
      "\n",
      "ind  [ 97 206 211 102 186  77]\n",
      "ind after  [ 97 206 211 102 186]\n",
      "done\n",
      "\n",
      "ind  [ 84 193 192  78 187  83]\n",
      "ind after  [ 84 193 192 187  83]\n",
      "done\n",
      "\n",
      "ind  [ 65 174 184  75  79 188]\n",
      "ind after  [ 65 174 184  75 188]\n",
      "done\n",
      "\n",
      "ind  [208  99 153  80 189  44]\n",
      "ind after  [208  99 153 189  44]\n",
      "done\n",
      "\n",
      "ind  [112   3  31 140 190  81]\n",
      "ind after  [112   3  31 140 190]\n",
      "done\n",
      "\n",
      "ind  [ 25 191  21  82 130 134]\n",
      "ind after  [ 25 191  21 130 134]\n",
      "done\n",
      "\n",
      "ind  [187  78 192  83  44 153]\n",
      "ind after  [187  78 192  44 153]\n",
      "done\n",
      "\n",
      "ind  [100  84 209 193  78 187]\n",
      "ind after  [100 209 193  78 187]\n",
      "done\n",
      "\n",
      "ind  [ 65 174 183  74 194  85]\n",
      "ind after  [ 65 174 183  74 194]\n",
      "done\n",
      "\n",
      "ind  [162  53 190  81  86 195]\n",
      "ind after  [162  53 190  81 195]\n",
      "done\n",
      "\n",
      "ind  [133  24 151  42  87 196]\n",
      "ind after  [133  24 151  42 196]\n",
      "done\n",
      "\n",
      "ind  [142  33  68 177  88 197]\n",
      "ind after  [142  33  68 177 197]\n",
      "done\n",
      "\n",
      "ind  [ 61 170 198 136  89  27]\n",
      "ind after  [ 61 170 198 136  27]\n",
      "done\n",
      "\n",
      "ind  [186  77 155  46 199  90]\n",
      "ind after  [186  77 155  46 199]\n",
      "done\n",
      "\n",
      "ind  [171  62 206  97  91 200]\n",
      "ind after  [171  62 206  97 200]\n",
      "done\n",
      "\n",
      "ind  [ 17 126  16 125 201  92]\n",
      "ind after  [ 17 126  16 125 201]\n",
      "done\n",
      "\n",
      "ind  [104 213 141 202  93  32]\n",
      "ind after  [104 213 141 202  32]\n",
      "done\n",
      "\n",
      "ind  [ 83 192  94 203  63 172]\n",
      "ind after  [ 83 192 203  63 172]\n",
      "done\n",
      "\n",
      "ind  [ 21 130  35 144  95 204]\n",
      "ind after  [ 21 130  35 144 204]\n",
      "done\n",
      "\n",
      "ind  [102 211 169  60  96 205]\n",
      "ind after  [102 211 169  60 205]\n",
      "done\n",
      "\n",
      "ind  [  5 114 185  76  97 206]\n",
      "ind after  [  5 114 185  76 206]\n",
      "done\n",
      "\n",
      "ind  [ 92 201 119  10  98 207]\n",
      "ind after  [ 92 201 119  10 207]\n",
      "done\n",
      "\n",
      "ind  [ 28 137 162  53 208  99]\n",
      "ind after  [ 28 137 162  53 208]\n",
      "done\n",
      "\n",
      "ind  [187  78 209 193  84 100]\n",
      "ind after  [187  78 209 193  84]\n",
      "done\n",
      "\n",
      "ind  [ 85 194  74 183 101 210]\n",
      "ind after  [ 85 194  74 183 210]\n",
      "done\n",
      "\n",
      "ind  [155  46  77 102 211 186]\n",
      "ind after  [155  46  77 211 186]\n",
      "done\n",
      "\n",
      "ind  [165  56 116 212   7 103]\n",
      "ind after  [165  56 116 212   7]\n",
      "done\n",
      "\n",
      "ind  [ 93 141  32 202 213 104]\n",
      "ind after  [ 93 141  32 202 213]\n",
      "done\n",
      "\n",
      "ind  [ 36 145  56 214 165 105]\n",
      "ind after  [ 36 145  56 214 165]\n",
      "done\n",
      "\n",
      "ind  [130  21 106 215  57 166]\n",
      "ind after  [130  21 215  57 166]\n",
      "done\n",
      "\n",
      "ind  [ 20 129 128  19 216 107]\n",
      "ind after  [ 20 129 128  19 216]\n",
      "done\n",
      "\n",
      "ind  [119  10 175  66 217 108]\n",
      "ind after  [119  10 175  66 217]\n",
      "done\n",
      "\n",
      "ind  [180  71   1 110 109   0]\n",
      "ind after  [180  71   1 110   0]\n",
      "done\n",
      "\n",
      "ind  [  0 156  47   1 110 109]\n",
      "ind after  [  0 156  47   1 109]\n",
      "done\n",
      "\n",
      "ind  [ 69 178 123  14   2 111]\n",
      "ind after  [ 69 178 123  14   2]\n",
      "done\n",
      "\n",
      "ind  [190  81 140 112   3  31]\n",
      "ind after  [190  81 140   3  31]\n",
      "done\n",
      "\n",
      "ind  [206  97 160 113   4  51]\n",
      "ind after  [206  97 160   4  51]\n",
      "done\n",
      "\n",
      "ind  [ 52  60 114   5 169 161]\n",
      "ind after  [ 52  60   5 169 161]\n",
      "done\n",
      "\n",
      "ind  [153  30   6 139  44 115]\n",
      "ind after  [153  30   6 139  44]\n",
      "done\n",
      "\n",
      "ind  [103 212 165  56   7 116]\n",
      "ind after  [103 212 165  56   7]\n",
      "done\n",
      "\n",
      "ind  [ 41 150 148  39   8 117]\n",
      "ind after  [ 41 150 148  39   8]\n",
      "done\n",
      "\n",
      "ind  [ 39 148 118   9   8 117]\n",
      "ind after  [ 39 148   9   8 117]\n",
      "done\n",
      "\n",
      "ind  [117 118  10   9   8 119]\n",
      "ind after  [117 118  10   9   8]\n",
      "done\n",
      "\n",
      "ind  [  9 118 119  10  11 120]\n",
      "ind after  [  9 118 119  10  11]\n",
      "done\n",
      "\n",
      "ind  [ 52 162 161  12 121  53]\n",
      "ind after  [ 52 162 161  12  53]\n",
      "done\n",
      "\n",
      "ind  [ 53 162  52 161 122  13]\n",
      "ind after  [ 53 162  52 161  13]\n",
      "done\n",
      "\n",
      "ind  [ 54 163 178 123  69  14]\n",
      "ind after  [ 54 163 178  69  14]\n",
      "done\n",
      "\n",
      "ind  [ 95 124  15 204  25 134]\n",
      "ind after  [ 95  15 204  25 134]\n",
      "done\n",
      "\n",
      "ind  [ 92 201  17 125 126  16]\n",
      "ind after  [ 92 201  17 126  16]\n",
      "done\n",
      "\n",
      "ind  [ 92 201  17 125 126  16]\n",
      "ind after  [ 92 201  17 125  16]\n",
      "done\n",
      "\n",
      "ind  [  5 114 185  76  18 127]\n",
      "ind after  [  5 114 185  76  18]\n",
      "done\n",
      "\n",
      "ind  [ 20 128  19 107 216 129]\n",
      "ind after  [ 20  19 107 216 129]\n",
      "done\n",
      "\n",
      "ind  [128  19 107  20 216 129]\n",
      "ind after  [128  19 107  20 216]\n",
      "done\n",
      "\n",
      "ind  [106 215  95  21 204 130]\n",
      "ind after  [106 215  95  21 204]\n",
      "done\n",
      "\n",
      "ind  [ 19 128 141  32 131  22]\n",
      "ind after  [ 19 128 141  32  22]\n",
      "done\n",
      "\n",
      "ind  [147  38 152  23 132  43]\n",
      "ind after  [147  38 152  23  43]\n",
      "done\n",
      "\n",
      "ind  [146  24 145  37 133  36]\n",
      "ind after  [146  24 145  37  36]\n",
      "done\n",
      "\n",
      "ind  [ 21 130 124  15 134  25]\n",
      "ind after  [ 21 130 124  15  25]\n",
      "done\n",
      "\n",
      "ind  [ 84 135 193  26 192  83]\n",
      "ind after  [ 84 193  26 192  83]\n",
      "done\n",
      "\n",
      "ind  [ 61 170  89 198  27 136]\n",
      "ind after  [ 61 170  89 198  27]\n",
      "done\n",
      "\n",
      "ind  [162  53  99 137  28 208]\n",
      "ind after  [162  53  99  28 208]\n",
      "done\n",
      "\n",
      "ind  [ 12 121  69 138  29 178]\n",
      "ind after  [ 12 121  69  29 178]\n",
      "done\n",
      "\n",
      "ind  [  6 115  44 153  30 139]\n",
      "ind after  [  6 115  44 153  30]\n",
      "done\n",
      "\n",
      "ind  [190  81  31 140   3 112]\n",
      "ind after  [190  81  31   3 112]\n",
      "done\n",
      "\n",
      "ind  [ 93 213 202 141 104  32]\n",
      "ind after  [ 93 213 202 104  32]\n",
      "done\n",
      "\n",
      "ind  [121  12  33 142  64 173]\n",
      "ind after  [121  12  33  64 173]\n",
      "done\n",
      "\n",
      "ind  [151  42  40 149  34 143]\n",
      "ind after  [151  42  40 149  34]\n",
      "done\n",
      "\n",
      "ind  [130  21 204  95  35 144]\n",
      "ind after  [130  21 204  95  35]\n",
      "done\n",
      "\n",
      "ind  [214 105  36 145 133  24]\n",
      "ind after  [214 105  36 133  24]\n",
      "done\n",
      "\n",
      "ind  [214 105  37  42 146 151]\n",
      "ind after  [214 105  37  42 151]\n",
      "done\n",
      "\n",
      "ind  [  8 117 148  39  38 147]\n",
      "ind after  [  8 117 148  39  38]\n",
      "done\n",
      "\n",
      "ind  [ 38 147   8 117  39 148]\n",
      "ind after  [ 38 147   8 117  39]\n",
      "done\n",
      "\n",
      "ind  [151  42  34 143  40 149]\n",
      "ind after  [151  42  34 143  40]\n",
      "done\n",
      "\n",
      "ind  [148  39  41 150   8 117]\n",
      "ind after  [148  39  41   8 117]\n",
      "done\n",
      "\n",
      "ind  [ 40 149 146  37  42 151]\n",
      "ind after  [ 40 149 146  37  42]\n",
      "done\n",
      "\n",
      "ind  [ 60 169  43  23 152 132]\n",
      "ind after  [ 60 169  43  23 132]\n",
      "done\n",
      "\n",
      "ind  [192 139  83  44  30 153]\n",
      "ind after  [192 139  83  44  30]\n",
      "done\n",
      "\n",
      "ind  [169  60 186  45  77 154]\n",
      "ind after  [169  60 186  45  77]\n",
      "done\n",
      "\n",
      "ind  [ 77 186  46 211 155 102]\n",
      "ind after  [ 77 186  46 211 102]\n",
      "done\n",
      "\n",
      "ind  [ 48 157 110  47   1 156]\n",
      "ind after  [ 48 157 110  47   1]\n",
      "done\n",
      "\n",
      "ind  [180  48  71 157 156  47]\n",
      "ind after  [180  48  71 156  47]\n",
      "done\n",
      "\n",
      "ind  [216 107 137 158  28  49]\n",
      "ind after  [216 107 137  28  49]\n",
      "done\n",
      "\n",
      "ind  [183  74 101 210 159  50]\n",
      "ind after  [183  74 101 210  50]\n",
      "done\n",
      "\n",
      "ind  [204  95 113 160   4  51]\n",
      "ind after  [204  95 113   4  51]\n",
      "done\n",
      "\n",
      "ind  [114   5 161  52 162  53]\n",
      "ind after  [114   5  52 162  53]\n",
      "done\n",
      "\n",
      "ind  [208  99  53 162 161  52]\n",
      "ind after  [208  99  53 161  52]\n",
      "done\n",
      "\n",
      "ind  [123  14  59  54 168 163]\n",
      "ind after  [123  14  59  54 168]\n",
      "done\n",
      "\n",
      "ind  [ 44 153  72 181  55 164]\n",
      "ind after  [ 44 153  72 181  55]\n",
      "done\n",
      "\n",
      "ind  [116   7 105 214 165  56]\n",
      "ind after  [116   7 105 214  56]\n",
      "done\n",
      "\n",
      "ind  [  8 117  57 215 106 166]\n",
      "ind after  [  8 117  57 215 106]\n",
      "done\n",
      "\n",
      "ind  [ 74 183 174  58  65 167]\n",
      "ind after  [ 74 183 174  58  65]\n",
      "done\n",
      "\n",
      "ind  [ 33 142 163 168  59  54]\n",
      "ind after  [ 33 142 163  59  54]\n",
      "done\n",
      "\n",
      "ind  [  5 114  96  60 205 169]\n",
      "ind after  [  5 114  96  60 205]\n",
      "done\n",
      "\n",
      "ind  [179 171 170  61  70  62]\n",
      "ind after  [179 171  61  70  62]\n",
      "done\n",
      "\n",
      "ind  [ 61 170  47 156  62 171]\n",
      "ind after  [ 61 170  47 156  62]\n",
      "done\n",
      "\n",
      "ind  [212 103 108 172  63 217]\n",
      "ind after  [212 103 108  63 217]\n",
      "done\n",
      "\n",
      "ind  [142  13 122  33  64 173]\n",
      "ind after  [142  13 122  33  64]\n",
      "done\n",
      "\n",
      "ind  [183  74  65  58 167 174]\n",
      "ind after  [183  74  65  58 167]\n",
      "done\n",
      "\n",
      "ind  [201  92 108 175  66 217]\n",
      "ind after  [201  92 108  66 217]\n",
      "done\n",
      "\n",
      "ind  [182  73  12 121  67 176]\n",
      "ind after  [182  73  12 121  67]\n",
      "done\n",
      "\n",
      "ind  [142  33 197  88  68 177]\n",
      "ind after  [142  33 197  88  68]\n",
      "done\n",
      "\n",
      "ind  [138  29  14 123  69 178]\n",
      "ind after  [138  29  14 123  69]\n",
      "done\n",
      "\n",
      "ind  [ 61 179 170  70  62 171]\n",
      "ind after  [ 61 170  70  62 171]\n",
      "done\n",
      "\n",
      "ind  [109   0 157 180  71  48]\n",
      "ind after  [109   0 157  71  48]\n",
      "done\n",
      "\n",
      "ind  [ 80 189  55 164  72 181]\n",
      "ind after  [ 80 189  55 164  72]\n",
      "done\n",
      "\n",
      "ind  [176 121  12 182  67  73]\n",
      "ind after  [176 121  12  67  73]\n",
      "done\n",
      "\n",
      "ind  [ 65 174  85 194  74 183]\n",
      "ind after  [ 65 174  85 194  74]\n",
      "done\n",
      "\n",
      "ind  [ 79 188  75  74 183 184]\n",
      "ind after  [ 79 188  75  74 183]\n",
      "done\n",
      "\n",
      "ind  [171  97  62 206 185  76]\n",
      "ind after  [171  97  62 206  76]\n",
      "done\n",
      "\n",
      "ind  [ 97 206 211 102 186  77]\n",
      "ind after  [ 97 206 211 102  77]\n",
      "done\n",
      "\n",
      "ind  [ 84 193 192  78 187  83]\n",
      "ind after  [ 84 193 192  78  83]\n",
      "done\n",
      "\n",
      "ind  [ 65 174 184  75  79 188]\n",
      "ind after  [ 65 174 184  75  79]\n",
      "done\n",
      "\n",
      "ind  [208  99 153  80 189  44]\n",
      "ind after  [208  99 153  80  44]\n",
      "done\n",
      "\n",
      "ind  [112   3  31 140  81 190]\n",
      "ind after  [112   3  31 140  81]\n",
      "done\n",
      "\n",
      "ind  [ 25 191  21  82 130 134]\n",
      "ind after  [ 25  21  82 130 134]\n",
      "done\n",
      "\n",
      "ind  [187  78 192  83  44 153]\n",
      "ind after  [187  78  83  44 153]\n",
      "done\n",
      "\n",
      "ind  [100  84 209 193  78 187]\n",
      "ind after  [100  84 209  78 187]\n",
      "done\n",
      "\n",
      "ind  [ 65 174 183  74 194  85]\n",
      "ind after  [ 65 174 183  74  85]\n",
      "done\n",
      "\n",
      "ind  [162  53 190  81  86 195]\n",
      "ind after  [162  53 190  81  86]\n",
      "done\n",
      "\n",
      "ind  [133  24 151  42  87 196]\n",
      "ind after  [133  24 151  42  87]\n",
      "done\n",
      "\n",
      "ind  [142  33  68 177  88 197]\n",
      "ind after  [142  33  68 177  88]\n",
      "done\n",
      "\n",
      "ind  [ 61 170 198 136  89  27]\n",
      "ind after  [ 61 170 136  89  27]\n",
      "done\n",
      "\n",
      "ind  [186  77 155  46 199  90]\n",
      "ind after  [186  77 155  46  90]\n",
      "done\n",
      "\n",
      "ind  [171  62 206  97  91 200]\n",
      "ind after  [171  62 206  97  91]\n",
      "done\n",
      "\n",
      "ind  [ 17 126  16 125  92 201]\n",
      "ind after  [ 17 126  16 125  92]\n",
      "done\n",
      "\n",
      "ind  [104 213 141 202  93  32]\n",
      "ind after  [104 213 141  93  32]\n",
      "done\n",
      "\n",
      "ind  [ 83 192  94 203  63 172]\n",
      "ind after  [ 83 192  94  63 172]\n",
      "done\n",
      "\n",
      "ind  [ 21 130  35 144  95 204]\n",
      "ind after  [ 21 130  35 144  95]\n",
      "done\n",
      "\n",
      "ind  [102 211 169  60  96 205]\n",
      "ind after  [102 211 169  60  96]\n",
      "done\n",
      "\n",
      "ind  [  5 114 185  76  97 206]\n",
      "ind after  [  5 114 185  76  97]\n",
      "done\n",
      "\n",
      "ind  [ 92 201 119  10  98 207]\n",
      "ind after  [ 92 201 119  10  98]\n",
      "done\n",
      "\n",
      "ind  [ 28 137 162  53  99 208]\n",
      "ind after  [ 28 137 162  53  99]\n",
      "done\n",
      "\n",
      "ind  [187  78 209 193  84 100]\n",
      "ind after  [187  78 193  84 100]\n",
      "done\n",
      "\n",
      "ind  [ 85 194  74 183 101 210]\n",
      "ind after  [ 85 194  74 183 101]\n",
      "done\n",
      "\n",
      "ind  [155  46  77 102 211 186]\n",
      "ind after  [155  46  77 102 186]\n",
      "done\n",
      "\n",
      "ind  [165  56 116 212   7 103]\n",
      "ind after  [165  56 116   7 103]\n",
      "done\n",
      "\n",
      "ind  [ 93 141  32 202 104 213]\n",
      "ind after  [ 93 141  32 202 104]\n",
      "done\n",
      "\n",
      "ind  [ 36 145  56 214 165 105]\n",
      "ind after  [ 36 145  56 165 105]\n",
      "done\n",
      "\n",
      "ind  [130  21 106 215  57 166]\n",
      "ind after  [130  21 106  57 166]\n",
      "done\n",
      "\n",
      "ind  [ 20 129 128  19 216 107]\n",
      "ind after  [ 20 129 128  19 107]\n",
      "done\n",
      "\n",
      "ind  [119  10 175  66 108 217]\n",
      "ind after  [119  10 175  66 108]\n",
      "done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "update_x_list=Doc_atr.objects.filter(documents__Document_library_id=libraryId).order_by('Doc_atr_id')\n",
    "    \n",
    "try:\n",
    "    X=load_vectors_info(libraryId,info)\n",
    "    all_id = load_all_id(libraryId)\n",
    "\n",
    "    res_sim = cosine_distances(X, X)\n",
    "\n",
    "    for pos,item in enumerate(update_x_list):\n",
    "\n",
    "        vec=item.Doc_atr_vec_json[info]['vec']\n",
    "        vec_float = list()\n",
    "        for e in vec:\n",
    "            vec_float.append(float(e))\n",
    "\n",
    "        ind = np.argpartition(res_sim[pos], -6)[-6:][:6] #find top 5 most sim doc\n",
    "        print('ind ',ind)\n",
    "        ind = ind[ind!=pos]\n",
    "        print('ind after ',ind)\n",
    "        item.Doc_atr_vec_json[info]['sim']= [all_id[index] for index in ind]\n",
    "\n",
    "        #item.Doc_atr_vec_json[info]['sim']=similarity_docs(vec_float,X,libraryId,all_id)\n",
    "        #item.save()\n",
    "        print('done\\n')\n",
    "\n",
    "    #Doc_atr.objects.bulk_update(update_x_list,['Doc_atr_vec_json'])\n",
    "\n",
    "except Exception as err:\n",
    "    raise Exception(err)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a9c7b7",
   "metadata": {},
   "source": [
    "## doc upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3deb7e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039bc3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bced5580",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect list of documents (api, files)\n",
    "\n",
    "ETL\n",
    "unify convention api/files into one \n",
    "validate documents \n",
    "preprocess/setup model instances into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e4fd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from django.core.exceptions import ValidationError\n",
    "\n",
    "#validators.py \n",
    "\n",
    "\n",
    "def validate_doc(sentence):\n",
    "    if sentence in [\"\",None]:# or not isEnglish(sentence):\n",
    "          return False \n",
    "\n",
    "    if '.' in sentence:\n",
    "        if dict(Counter(sentence))['.']/len(sentence)>0.2:\n",
    "              return False\n",
    "\n",
    "\n",
    "    word_min_count = 50\n",
    "    words = sentence.split(' ')\n",
    "    new_words = []\n",
    "    append = new_words.append\n",
    "    for word in words:\n",
    "    w = \"\".join([c for c in word if c.isalnum() and c != ''])\n",
    "    if w == \"\":\n",
    "      continue\n",
    "    append(w)\n",
    "\n",
    "    return len(new_words) >= word_min_count\n",
    "\n",
    "def validate_abstract(doc):\n",
    "    if not validate_doc(doc):\n",
    "        raise ValidationError(\"This document is not valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8440a76",
   "metadata": {},
   "source": [
    "## file handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e6c70b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is the work of A!'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class A():\n",
    "    def __call__(self):\n",
    "        return \"this is the work of A!\"\n",
    "    \n",
    "a = A()\n",
    "a()\n",
    "\n",
    "import pickle \n",
    "\n",
    "abytes = pickle.dumps(a)\n",
    "abytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1ed2ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First line\n",
      "Second line\n",
      "Third line\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "def create_file_object(data=None,verbose=True):\n",
    "    if not data:\n",
    "        data = 'First line\\nSecond line\\nThird line\\n'\n",
    "    f = io.StringIO(data)\n",
    "    if verbose:\n",
    "        for line in f:\n",
    "            print(line.strip())\n",
    "    return f\n",
    "\n",
    "uf_bytes = create_file_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d85d0022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is DATA\n",
      " Volume Serial Number is 34AD-C7C1\n",
      "\n",
      " Directory of D:\\Documents\\ubiai\\nlp\\Science_NLP_BE\\notebooks\n",
      "\n",
      "06/21/2022  04:40 PM    <DIR>          .\n",
      "06/21/2022  04:40 PM    <DIR>          ..\n",
      "06/21/2022  02:58 PM    <DIR>          .ipynb_checkpoints\n",
      "06/21/2022  04:40 PM            14,535 ptolome.ai.dev.ipynb\n",
      "06/21/2022  04:27 PM             1,388 uploaded_file_example_txt.pkl\n",
      "               2 File(s)         15,923 bytes\n",
      "               3 Dir(s)  264,027,832,320 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir .\\notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d185d0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "django.core.files.uploadedfile.InMemoryUploadedFile"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uf = pickle.load(open('./notebooks/uploaded_file_example_txt.pkl','rb'))\n",
    "type(uf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed6e4522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from django.core.files.storage import default_storage\n",
    "from django.core.files.base import ContentFile\n",
    "from django.core.files.uploadedfile import InMemoryUploadedFile\n",
    "\n",
    "def _get_file_item(item):\n",
    "    \n",
    "    path = default_storage.save('tmp', ContentFile(item.read()))\n",
    "    tmp_file = os.path.join(settings.MEDIA_ROOT, path)\n",
    "    ex = item.name.split('.')[-1]\n",
    "    return tmp_file,ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b93e1b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('D:\\\\Documents\\\\ubiai\\\\nlp\\\\Science_NLP_BE\\\\media\\\\tmp_ZYsJP8S', 'txt')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tup = _get_file_item(uf)\n",
    "tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73be20cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileHandler():\n",
    "    def __init__(self,file_object):\n",
    "        self.file_object = file_object \n",
    "        \n",
    "    def parse(self):\n",
    "        pass \n",
    "    \n",
    "    def get_allowed_files(self):\n",
    "        EXTENSIONS = ('txt','pdf','docx')\n",
    "        EXTENSIONS = (\"txt\",)\n",
    "        TABULAR_EXTENSIONS = ('csv',)\n",
    "        return (\"txt\",\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429435b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "\n",
    "def docx_to_text(doc_file):\n",
    "    doc = docx.Document(doc_file)\n",
    "    fullText = []\n",
    "    for para in doc.paragraphs:\n",
    "        fullText.append(para.text)\n",
    "    text = '\\n'.join(fullText)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5053f80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_file_item(item):\n",
    "    \n",
    "    path = default_storage.save('tmp', ContentFile(item.read()))\n",
    "    tmp_file = os.path.join(settings.MEDIA_ROOT, path)\n",
    "    ex = item.name.split('.')[-1]\n",
    "    return tmp_file,ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dadba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_file(tmp_file):\n",
    "  df = pd.read_csv(tmp_file)\n",
    "  df = df.fillna('empty')\n",
    "  ls = df.to_dict('records')\n",
    "  \n",
    "  return ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617347de",
   "metadata": {},
   "source": [
    "## Analytics/statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08827c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import pathlib \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8841641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='./static/Scientific_journal_list.xlsx'\n",
    "df_cat = pd.read_excel(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b035bd5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Rank', 'Source id', 'Title', 'Type', 'Issn', 'SJR',\n",
       "       'SJR Best Quartile', 'H index', 'Total Docs. (2020)',\n",
       "       'Total Docs. (3years)', 'Total Refs.', 'Total Cites (3years)',\n",
       "       'Citable Docs. (3years)', 'Cites / Doc. (2years)', 'Ref. / Doc.',\n",
       "       'Country', 'Region', 'Publisher', 'Coverage',\n",
       "       'Categories\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "681b89c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Source id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Type</th>\n",
       "      <th>Issn</th>\n",
       "      <th>SJR</th>\n",
       "      <th>SJR Best Quartile</th>\n",
       "      <th>H index</th>\n",
       "      <th>Total Docs. (2020)</th>\n",
       "      <th>Total Docs. (3years)</th>\n",
       "      <th>Total Refs.</th>\n",
       "      <th>Total Cites (3years)</th>\n",
       "      <th>Citable Docs. (3years)</th>\n",
       "      <th>Cites / Doc. (2years)</th>\n",
       "      <th>Ref. / Doc.</th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>28773</td>\n",
       "      <td>Ca-A Cancer Journal for Clinicians</td>\n",
       "      <td>journal</td>\n",
       "      <td>15424863\\t 00079235</td>\n",
       "      <td>62.937</td>\n",
       "      <td>Q1</td>\n",
       "      <td>168.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>3452.0</td>\n",
       "      <td>15499.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>126.34</td>\n",
       "      <td>73.45</td>\n",
       "      <td>United States</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>Wiley-Blackwell</td>\n",
       "      <td>1950-2020</td>\n",
       "      <td>Hematology (Q1); Oncology (Q1)\\t\\t\\t\\t\\t\\t\\t\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>19434</td>\n",
       "      <td>MMWR Recommendations and Reports</td>\n",
       "      <td>journal</td>\n",
       "      <td>10575987\\t 15458601</td>\n",
       "      <td>40.949</td>\n",
       "      <td>Q1</td>\n",
       "      <td>143.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>50</td>\n",
       "      <td>129.2</td>\n",
       "      <td>United States</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>Centers for Disease Control and Prevention (CDC)</td>\n",
       "      <td>1990-2020</td>\n",
       "      <td>Epidemiology (Q1); Health Information Manageme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>20315</td>\n",
       "      <td>Nature Reviews Molecular Cell Biology</td>\n",
       "      <td>journal</td>\n",
       "      <td>14710072\\t 14710080</td>\n",
       "      <td>37.461</td>\n",
       "      <td>Q1</td>\n",
       "      <td>431.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>8439.0</td>\n",
       "      <td>10844.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>32.83</td>\n",
       "      <td>73.38</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>Nature Publishing Group</td>\n",
       "      <td>2000-2020</td>\n",
       "      <td>Cell Biology (Q1); Molecular Biology (Q1)\\t\\t\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>29431</td>\n",
       "      <td>Quarterly Journal of Economics</td>\n",
       "      <td>journal</td>\n",
       "      <td>00335533\\t 15314650</td>\n",
       "      <td>34.573</td>\n",
       "      <td>Q1</td>\n",
       "      <td>259.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>2733.0</td>\n",
       "      <td>1945.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>16</td>\n",
       "      <td>68.33</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>1886-2020</td>\n",
       "      <td>Economics and Econometrics (Q1)\\t\\t\\t\\t\\t\\t\\t\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>21100812243</td>\n",
       "      <td>Nature Reviews Materials</td>\n",
       "      <td>journal</td>\n",
       "      <td>20588437</td>\n",
       "      <td>32.011</td>\n",
       "      <td>Q1</td>\n",
       "      <td>108.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>10632.0</td>\n",
       "      <td>11188.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>32.15</td>\n",
       "      <td>115.57</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>Nature Publishing Group</td>\n",
       "      <td>2016-2020</td>\n",
       "      <td>Biomaterials (Q1); Electronic\\t Optical and Ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank    Source id                                  Title     Type  \\\n",
       "0   1.0        28773     Ca-A Cancer Journal for Clinicians  journal   \n",
       "1   2.0        19434       MMWR Recommendations and Reports  journal   \n",
       "2   3.0        20315  Nature Reviews Molecular Cell Biology  journal   \n",
       "3   4.0        29431         Quarterly Journal of Economics  journal   \n",
       "4   5.0  21100812243               Nature Reviews Materials  journal   \n",
       "\n",
       "                  Issn     SJR SJR Best Quartile  H index  Total Docs. (2020)  \\\n",
       "0  15424863\\t 00079235  62.937                Q1    168.0                47.0   \n",
       "1  10575987\\t 15458601  40.949                Q1    143.0                10.0   \n",
       "2  14710072\\t 14710080  37.461                Q1    431.0               115.0   \n",
       "3  00335533\\t 15314650  34.573                Q1    259.0                40.0   \n",
       "4             20588437  32.011                Q1    108.0                92.0   \n",
       "\n",
       "   Total Docs. (3years)  Total Refs.  Total Cites (3years)  \\\n",
       "0                 119.0       3452.0               15499.0   \n",
       "1                   9.0       1292.0                 492.0   \n",
       "2                 338.0       8439.0               10844.0   \n",
       "3                 110.0       2733.0                1945.0   \n",
       "4                 264.0      10632.0               11188.0   \n",
       "\n",
       "   Citable Docs. (3years) Cites / Doc. (2years) Ref. / Doc.         Country  \\\n",
       "0                    80.0                126.34       73.45   United States   \n",
       "1                     9.0                    50       129.2   United States   \n",
       "2                   167.0                 32.83       73.38  United Kingdom   \n",
       "3                   109.0                    16       68.33  United Kingdom   \n",
       "4                   138.0                 32.15      115.57  United Kingdom   \n",
       "\n",
       "             Region                                         Publisher  \\\n",
       "0  Northern America                                   Wiley-Blackwell   \n",
       "1  Northern America  Centers for Disease Control and Prevention (CDC)   \n",
       "2    Western Europe                           Nature Publishing Group   \n",
       "3    Western Europe                           Oxford University Press   \n",
       "4    Western Europe                           Nature Publishing Group   \n",
       "\n",
       "    Coverage                                         Categories  \n",
       "0  1950-2020  Hematology (Q1); Oncology (Q1)\\t\\t\\t\\t\\t\\t\\t\\t...  \n",
       "1  1990-2020  Epidemiology (Q1); Health Information Manageme...  \n",
       "2  2000-2020  Cell Biology (Q1); Molecular Biology (Q1)\\t\\t\\...  \n",
       "3  1886-2020  Economics and Econometrics (Q1)\\t\\t\\t\\t\\t\\t\\t\\...  \n",
       "4  2016-2020  Biomaterials (Q1); Electronic\\t Optical and Ma...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_name = 'Categories\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'\n",
    "new_name = 'Categories'\n",
    "\n",
    "df = df_cat.rename(columns={to_name:new_name})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cb4a59c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Rank', 'Source id', 'Title', 'Type', 'Issn', 'SJR',\n",
       "       'SJR Best Quartile', 'H index', 'Total Docs. (2020)',\n",
       "       'Total Docs. (3years)', 'Total Refs.', 'Total Cites (3years)',\n",
       "       'Citable Docs. (3years)', 'Cites / Doc. (2years)', 'Ref. / Doc.',\n",
       "       'Country', 'Region', 'Publisher', 'Coverage', 'Categories'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e006776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./static/sc_journals_list.csv',encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6e4eeab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Documents\\\\ubiai\\\\nlp\\\\Science_NLP_BE'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "45c4f40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Rank', 'Source id', 'Title', 'Type', 'Issn', 'SJR',\n",
       "       'SJR Best Quartile', 'H index', 'Total Docs. (2020)',\n",
       "       'Total Docs. (3years)', 'Total Refs.', 'Total Cites (3years)',\n",
       "       'Citable Docs. (3years)', 'Cites / Doc. (2years)', 'Ref. / Doc.',\n",
       "       'Country', 'Region', 'Publisher', 'Coverage', 'Categories'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./static/sc_journals_list.csv',low_memory=False)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bc16b4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortlimit_frequency_dict(dic,limit):\n",
    "  sort = sorted(dic.items(),reverse=True, key=lambda item: item[1])[:limit]\n",
    "  return {k: v for k, v in sort}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7efc6cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = Documents.objects.filter(Document_library__Library_id=libraryId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "25137bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JournalCategorizer:\n",
    "    def __init__(self):\n",
    "        self.df = pd.read_csv('./static/sc_journals_list.csv',low_memory=False)\n",
    "#         journals = list(self.df['Title'])\n",
    "        self.journals = [j.lower() for j in list(self.df['Title'])]\n",
    "        self.categories = [' '.join(str(cat).split()) for cat in list(self.df['Categories'])] \n",
    "        \n",
    "    def __call__(self,data):\n",
    "        js = data\n",
    "        res = []\n",
    "        append = res.append\n",
    "        for j in js: \n",
    "          try:\n",
    "            index = self.journals.index(j.lower()) \n",
    "          except:\n",
    "            index = -1\n",
    "\n",
    "\n",
    "          cat = self.categories[index] if index != -1 else \"empty\"\n",
    "\n",
    "          append({\"Title\":j,\"index\":index,\"category\":cat})\n",
    "\n",
    "\n",
    "        cats = []\n",
    "\n",
    "        #seperate each category into proper categories\n",
    "        for r in res:\n",
    "          g = r['category'].split(';')\n",
    "          cats.extend(g) \n",
    "\n",
    "        dic = dict(Counter(cats))\n",
    "        sort = sortlimit_frequency_dict(dic,10)\n",
    "\n",
    "        return sort\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "161fee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorizer = JournalCategorizer()\n",
    "journals = [doc.Document_journal for doc in docs if doc.Document_journal!=\"\"] \n",
    "res = categorizer(journals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b8bc20c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'empty': 166,\n",
       " 'Agronomy and Crop Science (Q1)': 10,\n",
       " ' Physical and Theoretical Chemistry (Q1)': 6,\n",
       " ' Organic Chemistry (Q1)': 6,\n",
       " ' Biotechnology (Q2)': 6,\n",
       " ' Physics and Astronomy (miscellaneous) (Q1)': 6,\n",
       " ' Chemistry (miscellaneous) (Q1)': 6,\n",
       " 'Condensed Matter Physics (Q2)': 4,\n",
       " ' Materials Chemistry (Q2)': 4,\n",
       " ' Organic Chemistry (Q2)': 4}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8daa83d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocStatistician:\n",
    "    def __init__(self):\n",
    "        self.categorizer = JournalCategorizer()\n",
    "        \n",
    "    def __call__(self,docs):\n",
    "          years = [doc.Document_published_date for doc in docs if doc.Document_published_date!=\"\" ]\n",
    "          journals = [doc.Document_journal for doc in docs if doc.Document_journal!=\"\"] \n",
    "          authors = [str(doc.Document_authors).strip() for doc in docs if doc.Document_authors !=\"\"]\n",
    "\n",
    "                 #preprocessing for authors\n",
    "          ls = [a.split(',') for a in authors]\n",
    "          new_ls = []\n",
    "          for l in ls:\n",
    "            new_ls.extend(l)\n",
    "\n",
    "          authors_res = sortlimit_frequency_dict(dict(Counter(new_ls)),10)\n",
    "          years_res = sortlimit_frequency_dict(dict(Counter(years)),10)\n",
    "          journals_res = sortlimit_frequency_dict(dict(Counter(journals)),10)\n",
    "\n",
    "          ls_docs = [doc for doc in docs]\n",
    "          ls_docs = sorted(ls_docs, key=lambda x: x.Document_citation_count, reverse=True)\n",
    "          citationCounts = {x.Document_title[:50]+\"...\":int(x.Document_citation_count) for x in ls_docs if str(x.Document_citation_count).isnumeric()}\n",
    "\n",
    "          citationCounts_res = sortlimit_frequency_dict(dict(citationCounts),10)\n",
    "\n",
    "          categories_res = self.categorizer([j.lower() for j in journals])\n",
    "\n",
    "          return {\"authors\":authors_res,\n",
    "          \"years\":years_res,\n",
    "          \"journals\":journals_res,\n",
    "          \"citationCounts\":citationCounts_res,\n",
    "          \"categories\":categories_res}\n",
    "     \n",
    "doc_stats = DocStatistician()\n",
    "res = doc_stats(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "01b1dbb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'authors': {' Florent': 66,\n",
       "  ' Florent Allais': 30,\n",
       "  ' Patrick Balaguer': 10,\n",
       "  'Florent Allais': 10,\n",
       "  ' Fanny; Allais': 10,\n",
       "  ' Amandine L. Flourat': 8,\n",
       "  'Flourat': 8,\n",
       "  ' Jean-Hugues; Allais': 8,\n",
       "  'Burge': 8,\n",
       "  'Chemarin': 8},\n",
       " 'years': {'N/A': 218},\n",
       " 'journals': {'ACS Sustainable Chemistry & Engineering ': 20,\n",
       "  'Green Chemistry ': 18,\n",
       "  'Frontiers in Chemistry ': 14,\n",
       "  'Separation and Purification Technology ': 12,\n",
       "  'ChemSusChem ': 8,\n",
       "  'RSC Advances ': 8,\n",
       "  'Antioxidants ': 8,\n",
       "  'Molecules ': 8,\n",
       "  'Algal Research': 6,\n",
       "  'European Polymer Journal ': 6},\n",
       " 'citationCounts': {},\n",
       " 'categories': {'empty': 166,\n",
       "  'Agronomy and Crop Science (Q1)': 10,\n",
       "  ' Physical and Theoretical Chemistry (Q1)': 6,\n",
       "  ' Organic Chemistry (Q1)': 6,\n",
       "  ' Biotechnology (Q2)': 6,\n",
       "  ' Physics and Astronomy (miscellaneous) (Q1)': 6,\n",
       "  ' Chemistry (miscellaneous) (Q1)': 6,\n",
       "  'Condensed Matter Physics (Q2)': 4,\n",
       "  ' Materials Chemistry (Q2)': 4,\n",
       "  ' Organic Chemistry (Q2)': 4}}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89db3bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@timer\n",
    "def get_analytics(docs,categorizer):\n",
    "  \n",
    "  years = [doc.Document_published_date for doc in docs if doc.Document_published_date!=\"\" ]\n",
    "  journals = [doc.Document_journal for doc in docs if doc.Document_journal!=\"\"] \n",
    "  authors = [str(doc.Document_authors).strip() for doc in docs if doc.Document_authors !=\"\"]  \n",
    "\n",
    "  #preprocessing for authors\n",
    "  ls = [a.split(',') for a in authors]\n",
    "  new_ls = []\n",
    "  for l in ls:\n",
    "    new_ls.extend(l)\n",
    "\n",
    "  authors_res = sortlimit_frequency_dict(dict(Counter(new_ls)),10)\n",
    "  years_res = sortlimit_frequency_dict(dict(Counter(years)),10)\n",
    "  journals_res = sortlimit_frequency_dict(dict(Counter(journals)),10)\n",
    "\n",
    "  ls_docs = [doc for doc in docs]\n",
    "  ls_docs = sorted(ls_docs, key=lambda x: x.Document_citation_count, reverse=True)\n",
    "  citationCounts = {x.Document_title[:50]+\"...\":int(x.Document_citation_count) for x in ls_docs if str(x.Document_citation_count).isnumeric()}\n",
    "\n",
    "  #print(\"CITATION COUNTS \",citationCounts)\n",
    "\n",
    "  citationCounts_res = sortlimit_frequency_dict(dict(citationCounts),10)\n",
    "\n",
    "  js = [j.lower() for j in journals]\n",
    "  categories_res = categorizer.compute_category(js)\n",
    "\n",
    "  return {\"authors\":authors_res,\n",
    "  \"years\":years_res,\n",
    "  \"journals\":journals_res,\n",
    "  \"citationCounts\":citationCounts_res,\n",
    "  \"categories\":categories_res} "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
